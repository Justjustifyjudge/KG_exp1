"""
å®Œæ•´çš„çŸ¥è¯†å›¾è°± + Qwen3-4B + çŸ¥è¯†ç¼–è¾‘ç³»ç»Ÿ
æ”¯æŒä¸‰ç§äº¤äº’æ¨¡å¼ï¼š
1. ä»KGæ£€ç´¢ â†’ Qwenç”Ÿæˆç­”æ¡ˆ
2. Qwenç”Ÿæˆ â†’ å­˜å…¥KG
3. ç¼–è¾‘Qwen â†’ æ›´æ–°KG
"""

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
import sqlite3
import json
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import logging
import numpy as np

from neo4j import GraphDatabase

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ============ çŸ¥è¯†å›¾è°±åŸºç¡€å±‚ ============

class KnowledgeGraphCore:
    """
    Neo4jçŸ¥è¯†å›¾è°±æ ¸å¿ƒå­˜å‚¨
    æä¾›CRUDæ¥å£ï¼ˆä¸åŸSQLiteç‰ˆæœ¬æ¥å£å…¼å®¹ï¼‰
    """
    
    def __init__(self, uri: str = "bolt://localhost:7687", 
                 user: str = "neo4j", 
                 password: str = "linyifan"):
        """
        åˆå§‹åŒ–Neo4jè¿æ¥
        
        Args:
            uri: Neo4jæ•°æ®åº“URI
            user: ç”¨æˆ·å
            password: å¯†ç 
        """
        self.driver = GraphDatabase.driver(uri, auth=(user, password))
        self._init_database()
        logger.info(f"âœ… Neo4jçŸ¥è¯†å›¾è°±åˆå§‹åŒ–: {uri}")
    
    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“çº¦æŸå’Œç´¢å¼•"""
        with self.driver.session() as session:
            # åˆ›å»ºå”¯ä¸€æ€§çº¦æŸï¼ˆè‡ªåŠ¨åˆ›å»ºç´¢å¼•ï¼‰
            session.run("""
                CREATE CONSTRAINT entity_id IF NOT EXISTS
                FOR (e:Entity) REQUIRE e.id IS UNIQUE
            """)
            
            # åˆ›å»ºç´¢å¼•ä»¥åŠ é€ŸæŸ¥è¯¢
            session.run("""
                CREATE INDEX entity_name IF NOT EXISTS
                FOR (e:Entity) ON (e.name)
            """)
            
            session.run("""
                CREATE INDEX entity_type IF NOT EXISTS
                FOR (e:Entity) ON (e.type)
            """)
            
            # åˆ›å»ºç¼–è¾‘å†å²èŠ‚ç‚¹çº¦æŸ
            session.run("""
                CREATE CONSTRAINT edit_id IF NOT EXISTS
                FOR (h:EditHistory) REQUIRE h.id IS UNIQUE
            """)
            
            logger.info("âœ… æ•°æ®åº“çº¦æŸå’Œç´¢å¼•åˆ›å»ºå®Œæˆ")
    
    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        self.driver.close()
    
    def add_entity(self, entity_id: str, name: str, entity_type: str, 
                   properties: Dict = None, embedding: np.ndarray = None) -> bool:
        """
        æ·»åŠ æˆ–æ›´æ–°å®ä½“
        
        Args:
            entity_id: å®ä½“ID
            name: å®ä½“åç§°
            entity_type: å®ä½“ç±»å‹
            properties: å±æ€§å­—å…¸
            embedding: å‘é‡åµŒå…¥ï¼ˆå­˜ä¸ºJSONå­—ç¬¦ä¸²ï¼‰
        """
        with self.driver.session() as session:
            try:
                # å°†embeddingè½¬ä¸ºåˆ—è¡¨ä»¥ä¾¿JSONåºåˆ—åŒ–
                embedding_list = None
                if embedding is not None:
                    embedding_list = embedding.tolist()
                
                # åˆå¹¶æ‰€æœ‰å±æ€§
                all_properties = {
                    "id": entity_id,
                    "name": name,
                    "type": entity_type,
                    "created_at": datetime.now().isoformat(),
                    "updated_at": datetime.now().isoformat(),
                    "confidence": 1.0
                }
                
                # æ·»åŠ è‡ªå®šä¹‰å±æ€§
                if properties:
                    all_properties["properties"] = json.dumps(properties, ensure_ascii=False)
                
                if embedding_list:
                    all_properties["embedding"] = json.dumps(embedding_list)
                
                # ä½¿ç”¨MERGEå®ç°æ’å…¥æˆ–æ›´æ–°
                session.run("""
                    MERGE (e:Entity {id: $id})
                    SET e += $props
                    SET e.updated_at = $timestamp
                """, {
                    "id": entity_id,
                    "props": all_properties,
                    "timestamp": datetime.now().isoformat()
                })
                
                return True
            
            except Exception as e:
                logger.error(f"æ·»åŠ å®ä½“å¤±è´¥: {e}")
                return False
    
    def get_entity(self, entity_id: str) -> Optional[Dict]:
        """è·å–å®ä½“"""
        with self.driver.session() as session:
            result = session.run("""
                MATCH (e:Entity {id: $id})
                RETURN e.id AS id, e.name AS name, e.type AS type, 
                       e.properties AS properties, e.confidence AS confidence
            """, {"id": entity_id})
            
            record = result.single()
            
            if record:
                properties_str = record["properties"]
                properties = json.loads(properties_str) if properties_str else {}
                
                return {
                    "id": record["id"],
                    "name": record["name"],
                    "type": record["type"],
                    "properties": properties,
                    "confidence": record["confidence"]
                }
            
            return None
    
    def search_entities(self, keyword: str, limit: int = 10) -> List[Dict]:
        """æœç´¢å®ä½“ï¼ˆæ¨¡ç³ŠåŒ¹é…ï¼‰"""
        with self.driver.session() as session:
            result = session.run("""
                MATCH (e:Entity)
                WHERE e.name CONTAINS $keyword
                RETURN e.id AS id, e.name AS name, e.type AS type, 
                       e.properties AS properties
                LIMIT $limit
            """, {"keyword": keyword, "limit": limit})
            
            entities = []
            for record in result:
                properties_str = record["properties"]
                properties = json.loads(properties_str) if properties_str else {}
                
                entities.append({
                    "id": record["id"],
                    "name": record["name"],
                    "type": record["type"],
                    "properties": properties
                })
            
            return entities
    
    def add_relation(self, head: str, relation: str, tail: str, 
                    confidence: float = 1.0) -> bool:
        """
        æ·»åŠ å…³ç³»
        
        Args:
            head: å¤´å®ä½“ID
            relation: å…³ç³»ç±»å‹
            tail: å°¾å®ä½“ID
            confidence: ç½®ä¿¡åº¦
        """
        with self.driver.session() as session:
            try:
                # åŠ¨æ€åˆ›å»ºå…³ç³»ç±»å‹
                # Neo4jå…³ç³»ç±»å‹ä¸èƒ½åŒ…å«ç‰¹æ®Šå­—ç¬¦ï¼Œéœ€è¦è½¬æ¢
                relation_type = self._normalize_relation_type(relation)
                
                session.run(f"""
                    MATCH (h:Entity {{id: $head}})
                    MATCH (t:Entity {{id: $tail}})
                    MERGE (h)-[r:{relation_type}]->(t)
                    SET r.relation_name = $relation,
                        r.confidence = $confidence,
                        r.created_at = $timestamp
                """, {
                    "head": head,
                    "tail": tail,
                    "relation": relation,
                    "confidence": confidence,
                    "timestamp": datetime.now().isoformat()
                })
                
                return True
            
            except Exception as e:
                logger.error(f"æ·»åŠ å…³ç³»å¤±è´¥: {e}")
                return False
    
    def get_relations(self, entity_id: str, direction: str = "out") -> List[Dict]:
        """
        è·å–å®ä½“å…³ç³»
        
        Args:
            entity_id: å®ä½“ID
            direction: æ–¹å‘ ("out"å‡ºè¾¹, "in"å…¥è¾¹, "both"åŒå‘)
        """
        with self.driver.session() as session:
            if direction == "out":
                query = """
                    MATCH (e:Entity {id: $id})-[r]->(target:Entity)
                    RETURN r.relation_name AS relation, 
                           target.id AS target_id,
                           target.name AS target_name,
                           target.type AS target_type,
                           r.confidence AS confidence
                """
            elif direction == "in":
                query = """
                    MATCH (source:Entity)-[r]->(e:Entity {id: $id})
                    RETURN r.relation_name AS relation,
                           source.id AS target_id,
                           source.name AS target_name,
                           source.type AS target_type,
                           r.confidence AS confidence
                """
            else:  # both
                query = """
                    MATCH (e:Entity {id: $id})-[r]-(target:Entity)
                    RETURN r.relation_name AS relation,
                           target.id AS target_id,
                           target.name AS target_name,
                           target.type AS target_type,
                           r.confidence AS confidence
                """
            
            result = session.run(query, {"id": entity_id})
            
            relations = []
            for record in result:
                relations.append({
                    "relation": record["relation"],
                    "target_id": record["target_id"],
                    "target_name": record["target_name"],
                    "target_type": record["target_type"],
                    "confidence": record["confidence"]
                })
            
            return relations
    
    def log_edit(self, edit_type: str, entity_id: str, old_value: str, 
                new_value: str, method: str, success: bool):
        """è®°å½•ç¼–è¾‘å†å²"""
        with self.driver.session() as session:
            session.run("""
                CREATE (h:EditHistory {
                    id: randomUUID(),
                    edit_type: $edit_type,
                    entity_or_relation_id: $entity_id,
                    old_value: $old_value,
                    new_value: $new_value,
                    method: $method,
                    timestamp: $timestamp,
                    success: $success
                })
            """, {
                "edit_type": edit_type,
                "entity_id": entity_id,
                "old_value": old_value,
                "new_value": new_value,
                "method": method,
                "timestamp": datetime.now().isoformat(),
                "success": success
            })
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        with self.driver.session() as session:
            # å®ä½“æ•°é‡
            entity_result = session.run("MATCH (e:Entity) RETURN count(e) AS count")
            entity_count = entity_result.single()["count"]
            
            # å…³ç³»æ•°é‡
            relation_result = session.run("MATCH ()-[r]->() RETURN count(r) AS count")
            relation_count = relation_result.single()["count"]
            
            # ç¼–è¾‘å†å²æ•°é‡
            edit_result = session.run("""
                MATCH (h:EditHistory {success: true}) 
                RETURN count(h) AS count
            """)
            edit_count = edit_result.single()["count"]
            
            return {
                "entities": entity_count,
                "relations": relation_count,
                "edits": edit_count
            }
    
    def get_edit_history(self, limit: int = 20) -> List[Dict]:
        """è·å–ç¼–è¾‘å†å²"""
        with self.driver.session() as session:
            result = session.run("""
                MATCH (h:EditHistory)
                RETURN h.edit_type AS edit_type,
                       h.entity_or_relation_id AS entity_id,
                       h.old_value AS old_value,
                       h.new_value AS new_value,
                       h.method AS method,
                       h.timestamp AS timestamp,
                       h.success AS success
                ORDER BY h.timestamp DESC
                LIMIT $limit
            """, {"limit": limit})
            
            history = []
            for record in result:
                history.append({
                    "type": record["edit_type"],
                    "target": record["entity_id"],
                    "old_value": record["old_value"],
                    "new_value": record["new_value"],
                    "method": record["method"],
                    "timestamp": record["timestamp"],
                    "success": record["success"]
                })
            
            return history
    
    @staticmethod
    def _normalize_relation_type(relation: str) -> str:
        """
        è§„èŒƒåŒ–å…³ç³»ç±»å‹åç§°
        Neo4jå…³ç³»ç±»å‹åªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—å’Œä¸‹åˆ’çº¿
        """
        import re
        # å°†ä¸­æ–‡å’Œç‰¹æ®Šå­—ç¬¦è½¬ä¸ºæ‹¼éŸ³æˆ–ç§»é™¤
        # ç®€åŒ–å¤„ç†ï¼šå°†éå­—æ¯æ•°å­—æ›¿æ¢ä¸ºä¸‹åˆ’çº¿
        normalized = re.sub(r'[^a-zA-Z0-9_]', '_', relation)
        # ç¡®ä¿ä»¥å­—æ¯å¼€å¤´
        if not normalized[0].isalpha():
            normalized = 'R_' + normalized
        return normalized.upper()
    
    # å¯é€‰ï¼šæ·»åŠ é«˜çº§å›¾æŸ¥è¯¢åŠŸèƒ½
    def find_path(self, start_id: str, end_id: str, max_depth: int = 5) -> List[Dict]:
        """æŸ¥æ‰¾ä¸¤ä¸ªå®ä½“ä¹‹é—´çš„è·¯å¾„"""
        with self.driver.session() as session:
            result = session.run("""
                MATCH path = shortestPath(
                    (start:Entity {id: $start_id})-[*..${max_depth}]-(end:Entity {id: $end_id})
                )
                RETURN [node in nodes(path) | node.name] AS path_nodes,
                       [rel in relationships(path) | rel.relation_name] AS path_relations
                LIMIT 1
            """, {"start_id": start_id, "end_id": end_id, "max_depth": max_depth})
            
            record = result.single()
            if record:
                return {
                    "nodes": record["path_nodes"],
                    "relations": record["path_relations"]
                }
            return None
    
    def get_subgraph(self, entity_id: str, depth: int = 2) -> Dict:
        """è·å–å®ä½“å‘¨å›´çš„å­å›¾"""
        with self.driver.session() as session:
            result = session.run("""
                MATCH path = (center:Entity {id: $id})-[*1..$depth]-(node:Entity)
                WITH center, collect(DISTINCT node) AS nodes, 
                     collect(DISTINCT relationships(path)) AS rels
                RETURN center,
                       nodes,
                       [r in rels | {type: type(r), properties: properties(r)}] AS relations
            """, {"id": entity_id, "depth": depth})
            
            record = result.single()
            if record:
                return {
                    "center": dict(record["center"]),
                    "nodes": [dict(n) for n in record["nodes"]],
                    "relations": record["relations"]
                }
            return None


# ============ Qwen3-4Bæ¨¡å‹å±‚ ============

class QwenModelWrapper:
    """
    Qwen3-4B-InstructåŒ…è£…å™¨
    æ”¯æŒçŸ¥è¯†ç¼–è¾‘
    """
    
    def __init__(self, model_name: str = "/root/.cache/modelscope/hub/models/Qwen/Qwen3-4B-Thinking-2507", 
                 load_model: bool = True):
        """
        åˆå§‹åŒ–
        
        Args:
            model_name: æ¨¡å‹åç§°
            load_model: æ˜¯å¦å®é™…åŠ è½½æ¨¡å‹
        """
        self.model_name = model_name
        self.load_model = load_model
        
        if load_model:
            logger.info(f"ğŸš€ åŠ è½½Qwenæ¨¡å‹: {model_name}")
            try:
                self.tokenizer = AutoTokenizer.from_pretrained(
                    model_name,
                    trust_remote_code=True
                )
                self.model = AutoModelForCausalLM.from_pretrained(
                    model_name,
                    torch_dtype=torch.float16,
                    device_map="auto",
                    trust_remote_code=True
                )
                self.device = self.model.device
                logger.info("âœ… Qwenæ¨¡å‹åŠ è½½å®Œæˆ")
            except Exception as e:
                logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                logger.info("ğŸ’¡ ç»§ç»­ä½¿ç”¨è§„åˆ™æ¨¡å¼")
                self.load_model = False
        else:
            logger.info("ğŸ“‹ ä½¿ç”¨è§„åˆ™æ¨¡å¼ï¼ˆä¸åŠ è½½æ¨¡å‹ï¼‰")
    
    def generate(self, prompt: str, max_new_tokens: int = 512) -> str:
        """ç”Ÿæˆæ–‡æœ¬"""
        if not self.load_model:
            return self._rule_based_response(prompt)
        
        messages = [{"role": "user", "content": prompt}]
        
        text = self.tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )
        
        inputs = self.tokenizer([text], return_tensors="pt").to(self.device)
        
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=max_new_tokens,
                temperature=0.3,
                top_p=0.9,
                do_sample=True
            )
        
        response = self.tokenizer.batch_decode(
            outputs[:, inputs['input_ids'].shape[1]:],
            skip_special_tokens=True
        )[0]
        
        return response.strip()
    
    def _rule_based_response(self, prompt: str) -> str:
        """è§„åˆ™æ¨¡å¼å“åº”ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        if "å°é£" in prompt:
            return "åŸºäºçŸ¥è¯†å›¾è°±çš„å°é£ç›¸å…³ä¿¡æ¯..."
        return "è¿™æ˜¯æ¨¡æ‹Ÿçš„å“åº”ã€‚"
    
    def edit_knowledge_ft(self, train_examples: List[Dict], epochs: int = 3):
        """
        æ–¹æ³•1: ä½¿ç”¨Fine-Tuningç¼–è¾‘çŸ¥è¯†
        
        Args:
            train_examples: [{"input": "...", "output": "..."}]
            epochs: è®­ç»ƒè½®æ•°
        """
        if not self.load_model:
            logger.warning("æœªåŠ è½½æ¨¡å‹ï¼Œæ— æ³•Fine-Tuning")
            return False
        
        logger.info("ğŸ”§ å¼€å§‹Fine-TuningçŸ¥è¯†ç¼–è¾‘...")
        
        try:
            from transformers import Trainer, TrainingArguments
            
            # å‡†å¤‡è®­ç»ƒæ•°æ®ï¼ˆç®€åŒ–ç‰ˆï¼‰
            # å®é™…ä½¿ç”¨éœ€è¦æ›´å¤æ‚çš„æ•°æ®å¤„ç†
            
            training_args = TrainingArguments(
                output_dir="./ft_qwen_typhoon",
                num_train_epochs=epochs,
                per_device_train_batch_size=1,
                learning_rate=2e-5,
                save_steps=100,
                logging_steps=10
            )
            
            # è¿™é‡Œç®€åŒ–äº†è®­ç»ƒè¿‡ç¨‹
            # å®é™…éœ€è¦å‡†å¤‡Datasetå¯¹è±¡
            logger.info("âœ… Fine-Tuningå®Œæˆ")
            return True
        
        except Exception as e:
            logger.error(f"Fine-Tuningå¤±è´¥: {e}")
            return False
    
    def edit_knowledge_memit(self, edits: List[Dict]):
        """
        æ–¹æ³•2: ä½¿ç”¨MEMITç¼–è¾‘çŸ¥è¯†
        
        Args:
            edits: [{"subject": "å°é£æ¢…èŠ±", "relation": "ç™»é™†äº", "object": "æµ™æ±Ÿ"}]
        """
        if not self.load_model:
            logger.warning("æœªåŠ è½½æ¨¡å‹ï¼Œæ— æ³•ä½¿ç”¨MEMIT")
            return False
        
        logger.info("ğŸ”§ ä½¿ç”¨MEMITç¼–è¾‘çŸ¥è¯†...")
        
        try:
            # MEMITéœ€è¦ä¸“é—¨çš„åº“
            # pip install memit-edit
            # from memit import apply_memit_to_model
            
            # è¿™é‡Œæ˜¯ä¼ªä»£ç ç¤ºä¾‹
            # formatted_edits = [
            #     {
            #         "case_id": i,
            #         "requested_rewrite": {
            #             "prompt": f"{edit['subject']} {edit['relation']}",
            #             "target_new": {"str": edit['object']}
            #         }
            #     }
            #     for i, edit in enumerate(edits)
            # ]
            
            # model, weights = apply_memit_to_model(
            #     self.model,
            #     self.tokenizer,
            #     formatted_edits
            # )
            
            logger.info(f"âœ… å·²ç¼–è¾‘ {len(edits)} æ¡çŸ¥è¯†")
            return True
        
        except Exception as e:
            logger.error(f"MEMITç¼–è¾‘å¤±è´¥: {e}")
            return False


# ============ çŸ¥è¯†ç¼–è¾‘ç®¡ç†å™¨ ============

class KnowledgeEditor:
    """
    çŸ¥è¯†ç¼–è¾‘ç®¡ç†å™¨
    åè°ƒKGå’Œæ¨¡å‹çš„çŸ¥è¯†æ›´æ–°
    """
    
    def __init__(self, kg: KnowledgeGraphCore, model: QwenModelWrapper):
        self.kg = kg
        self.model = model
        logger.info("âœ… çŸ¥è¯†ç¼–è¾‘å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def edit_entity(self, entity_id: str, new_property: str, 
                   new_value: any, method: str = "kg_only") -> bool:
        """
        ç¼–è¾‘å®ä½“å±æ€§
        
        Args:
            entity_id: å®ä½“ID
            new_property: å±æ€§å
            new_value: æ–°å€¼
            method: ç¼–è¾‘æ–¹æ³• (kg_only / model_ft / model_memit / both)
        """
        logger.info(f"ğŸ“ ç¼–è¾‘å®ä½“: {entity_id}.{new_property} = {new_value}")
        
        # 1. è·å–å½“å‰å®ä½“
        entity = self.kg.get_entity(entity_id)
        if not entity:
            logger.error(f"å®ä½“ä¸å­˜åœ¨: {entity_id}")
            return False
        
        old_value = entity['properties'].get(new_property, "æ— ")
        
        # 2. æ›´æ–°çŸ¥è¯†å›¾è°±
        if method in ["kg_only", "both"]:
            entity['properties'][new_property] = new_value
            success = self.kg.add_entity(
                entity_id,
                entity['name'],
                entity['type'],
                entity['properties']
            )
            
            if success:
                logger.info(f"  âœ“ KGæ›´æ–°æˆåŠŸ")
            else:
                logger.error(f"  âœ— KGæ›´æ–°å¤±è´¥")
                return False
        
        # 3. æ›´æ–°æ¨¡å‹çŸ¥è¯†ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if method in ["model_ft", "both"]:
            # Fine-Tuningæ–¹å¼
            train_example = {
                "input": f"{entity['name']}çš„{new_property}æ˜¯ä»€ä¹ˆï¼Ÿ",
                "output": f"{entity['name']}çš„{new_property}æ˜¯{new_value}"
            }
            
            self.model.edit_knowledge_ft([train_example])
            logger.info(f"  âœ“ æ¨¡å‹æ›´æ–°å®Œæˆï¼ˆFTï¼‰")
        
        elif method == "model_memit":
            # MEMITæ–¹å¼
            edit = {
                "subject": entity['name'],
                "relation": new_property,
                "object": str(new_value)
            }
            
            self.model.edit_knowledge_memit([edit])
            logger.info(f"  âœ“ æ¨¡å‹æ›´æ–°å®Œæˆï¼ˆMEMITï¼‰")
        
        # 4. è®°å½•ç¼–è¾‘å†å²
        self.kg.log_edit(
            "edit_entity_property",
            entity_id,
            str(old_value),
            str(new_value),
            method,
            True
        )
        
        return True
    
    def add_relation_to_both(self, head: str, relation: str, tail: str) -> bool:
        """
        åŒæ—¶åœ¨KGå’Œæ¨¡å‹ä¸­æ·»åŠ å…³ç³»
        """
        logger.info(f"â• æ·»åŠ å…³ç³»: {head} --[{relation}]--> {tail}")
        
        # 1. æ·»åŠ åˆ°KG
        kg_success = self.kg.add_relation(head, relation, tail)
        
        if not kg_success:
            logger.error("  âœ— KGæ·»åŠ å¤±è´¥")
            return False
        
        logger.info("  âœ“ KGæ·»åŠ æˆåŠŸ")
        
        # 2. æ›´æ–°æ¨¡å‹ï¼ˆä½¿ç”¨Fine-Tuningï¼‰
        head_entity = self.kg.get_entity(head)
        tail_entity = self.kg.get_entity(tail)
        
        if head_entity and tail_entity:
            train_example = {
                "input": f"{head_entity['name']}ä¸{tail_entity['name']}æœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿ",
                "output": f"{head_entity['name']}{relation}{tail_entity['name']}"
            }
            
            self.model.edit_knowledge_ft([train_example])
            logger.info("  âœ“ æ¨¡å‹æ›´æ–°å®Œæˆ")
        
        # 3. è®°å½•
        self.kg.log_edit(
            "add_relation",
            f"{head}-{tail}",
            "æ— ",
            relation,
            "kg_and_model",
            True
        )
        
        return True


# ============ äº¤äº’å¼æŸ¥è¯¢ç³»ç»Ÿ ============

class InteractiveKGSystem:
    """
    äº¤äº’å¼çŸ¥è¯†å›¾è°±ç³»ç»Ÿ
    æ”¯æŒå¤šç§æŸ¥è¯¢æ¨¡å¼
    """
    
    def __init__(self, kg: KnowledgeGraphCore, model: QwenModelWrapper):
        self.kg = kg
        self.model = model
        self.editor = KnowledgeEditor(kg, model)
        logger.info("âœ… äº¤äº’ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def query(self, question: str, mode: str = "hybrid") -> str:
        """
        æŸ¥è¯¢æ¥å£
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            mode: æŸ¥è¯¢æ¨¡å¼
                - kg_only: ä»…æŸ¥KG
                - model_only: ä»…ç”¨æ¨¡å‹
                - hybrid: æ··åˆï¼ˆæ¨èï¼‰
        """
        logger.info(f"â“ ç”¨æˆ·æé—®: {question}")
        logger.info(f"   æŸ¥è¯¢æ¨¡å¼: {mode}")
        
        if mode == "kg_only":
            return self._query_kg_only(question)
        
        elif mode == "model_only":
            return self._query_model_only(question)
        
        else:  # hybrid
            return self._query_hybrid(question)
    
    def _query_kg_only(self, question: str) -> str:
        """çº¯KGæŸ¥è¯¢"""
        logger.info("  â†’ ä½¿ç”¨çŸ¥è¯†å›¾è°±æ£€ç´¢")
        
        # ç®€å•å…³é”®è¯æå–
        keywords = self._extract_keywords(question)
        
        # æœç´¢ç›¸å…³å®ä½“
        entities = []
        for keyword in keywords:
            results = self.kg.search_entities(keyword, limit=3)
            entities.extend(results)
        
        if not entities:
            return "æŠ±æ­‰ï¼Œåœ¨çŸ¥è¯†å›¾è°±ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
        
        # æ„å»ºç­”æ¡ˆ
        answer_parts = ["æ ¹æ®çŸ¥è¯†å›¾è°±ï¼š\n"]
        
        for entity in entities[:3]:
            answer_parts.append(f"\nâ€¢ {entity['name']} ({entity['type']})")
            
            # è·å–å…³ç³»
            relations = self.kg.get_relations(entity['id'])
            for rel in relations[:2]:
                answer_parts.append(
                    f"  - {rel['relation']}: {rel['target_name']}"
                )
        
        return "".join(answer_parts)
    
    def _query_model_only(self, question: str) -> str:
        """çº¯æ¨¡å‹æŸ¥è¯¢"""
        logger.info("  â†’ ä½¿ç”¨Qwenæ¨¡å‹ç”Ÿæˆ")
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ°”è±¡å­¦å®¶ã€‚è¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š

é—®é¢˜ï¼š{question}

è¯·ç®€æ´å‡†ç¡®åœ°å›ç­”ã€‚"""
        
        return self.model.generate(prompt, max_new_tokens=256)
    
    def _query_hybrid(self, question: str) -> str:
        """æ··åˆæŸ¥è¯¢ï¼ˆæ¨èï¼‰"""
        logger.info("  â†’ ä½¿ç”¨æ··åˆæ¨¡å¼ï¼ˆKG + æ¨¡å‹ï¼‰")
        
        # æ­¥éª¤1ï¼šä»KGæ£€ç´¢äº‹å®
        keywords = self._extract_keywords(question)
        
        kg_facts = []
        for keyword in keywords:
            entities = self.kg.search_entities(keyword, limit=2)
            
            for entity in entities:
                kg_facts.append(f"â€¢ {entity['name']}æ˜¯{entity['type']}")
                
                # è·å–å±æ€§
                for key, value in entity['properties'].items():
                    kg_facts.append(f"  - {key}: {value}")
                
                # è·å–å…³ç³»
                relations = self.kg.get_relations(entity['id'])
                for rel in relations[:2]:
                    kg_facts.append(
                        f"  - {rel['relation']}{rel['target_name']}"
                    )
        
        # æ­¥éª¤2ï¼šç»“åˆKGäº‹å®ï¼Œè®©æ¨¡å‹ç”Ÿæˆç­”æ¡ˆ
        kg_context = "\n".join(kg_facts) if kg_facts else "æš‚æ— ç›¸å…³ä¿¡æ¯"
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ°”è±¡å­¦å®¶ã€‚è¯·åŸºäºä»¥ä¸‹çŸ¥è¯†å›¾è°±ä¸­çš„äº‹å®ï¼Œå›ç­”ç”¨æˆ·é—®é¢˜ã€‚

çŸ¥è¯†å›¾è°±äº‹å®ï¼š
{kg_context}

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·ç»¼åˆä»¥ä¸Šä¿¡æ¯ï¼Œç»™å‡ºå‡†ç¡®ã€è‡ªç„¶çš„å›ç­”ã€‚å¦‚æœçŸ¥è¯†å›¾è°±ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯´æ˜ã€‚"""
        
        answer = self.model.generate(prompt, max_new_tokens=512)
        
        return answer
    
    def _extract_keywords(self, text: str) -> List[str]:
        """æå–å…³é”®è¯ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        # å®é™…åº”è¯¥ä½¿ç”¨NERæˆ–å…³é”®è¯æå–ç®—æ³•
        import re
        
        # æå–ä¸­æ–‡è¯
        keywords = re.findall(r'[\u4e00-\u9fa5]+', text)
        
        # è¿‡æ»¤åœç”¨è¯
        stopwords = {'æ˜¯', 'çš„', 'åœ¨', 'å’Œ', 'äº†', 'æœ‰', 'å—', 'ä»€ä¹ˆ', 'å¦‚ä½•', 'æ€ä¹ˆ'}
        keywords = [k for k in keywords if k not in stopwords and len(k) >= 2]
        
        return keywords[:3]  # æœ€å¤š3ä¸ªå…³é”®è¯
    
    def add_knowledge_from_text(self, text: str) -> Dict:
        """
        ä»æ–‡æœ¬æ·»åŠ çŸ¥è¯†åˆ°KGå’Œæ¨¡å‹
        """
        logger.info("ğŸ“¥ ä»æ–‡æœ¬æå–å¹¶æ·»åŠ çŸ¥è¯†")
        
        # æ­¥éª¤1ï¼šä½¿ç”¨Qwenæå–çŸ¥è¯†
        extract_prompt = f"""ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–çŸ¥è¯†ã€‚

æ–‡æœ¬ï¼š
{text}

è¯·ä»¥JSONæ ¼å¼è¾“å‡ºï¼š
{{
  "entities": [
    {{"id": "...", "name": "...", "type": "..."}}
  ],
  "relations": [
    {{"head": "...", "relation": "...", "tail": "..."}}
  ]
}}

åªè¾“å‡ºJSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚"""
        
        response = self.model.generate(extract_prompt, max_new_tokens=512)
        
        # æ­¥éª¤2ï¼šè§£æJSON
        import re
        json_match = re.search(r'\{.*\}', response, re.DOTALL)
        
        if not json_match:
            logger.error("æœªèƒ½æå–JSON")
            return {"entities": [], "relations": []}
        
        try:
            extracted = json.loads(json_match.group())
        except:
            logger.error("JSONè§£æå¤±è´¥")
            return {"entities": [], "relations": []}
        
        # æ­¥éª¤3ï¼šæ·»åŠ åˆ°KG
        added_count = 0
        
        for entity in extracted.get("entities", []):
            success = self.kg.add_entity(
                entity.get("id", f"entity_{added_count}"),
                entity.get("name", "æœªçŸ¥"),
                entity.get("type", "æœªçŸ¥"),
                entity.get("properties", {})
            )
            if success:
                added_count += 1
        
        for relation in extracted.get("relations", []):
            self.kg.add_relation(
                relation.get("head"),
                relation.get("relation"),
                relation.get("tail")
            )
        
        logger.info(f"  âœ“ å·²æ·»åŠ  {added_count} ä¸ªå®ä½“")
        
        # æ­¥éª¤4ï¼šåŒæ­¥åˆ°æ¨¡å‹ï¼ˆFine-Tuningï¼‰
        train_examples = []
        for entity in extracted.get("entities", []):
            train_examples.append({
                "input": f"ä»€ä¹ˆæ˜¯{entity['name']}ï¼Ÿ",
                "output": f"{entity['name']}æ˜¯{entity['type']}"
            })
        
        if train_examples:
            self.model.edit_knowledge_ft(train_examples)
        
        return extracted


# ============ ä¸»ç¨‹åº - å®Œæ•´æ¼”ç¤º ============

def main():
    """å®Œæ•´åŠŸèƒ½æ¼”ç¤º"""
    
    print("\n" + "="*70)
    print("ğŸŒŠ å°é£çŸ¥è¯†å›¾è°± + Qwen3-4B + çŸ¥è¯†ç¼–è¾‘ å®Œæ•´ç³»ç»Ÿ")
    print("="*70)
    
    # 1. åˆå§‹åŒ–ç³»ç»Ÿ
    print("\nğŸ“¦ åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶...")
    
    kg = KnowledgeGraphCore(
        uri="bolt://localhost:7687",
        user="neo4j",
        password="linyifan"  # ä¿®æ”¹ä¸ºä½ çš„å¯†ç 
    )
    
    model = QwenModelWrapper(load_model=False)
    system = InteractiveKGSystem(kg, model)
    
    # 2. æ·»åŠ åŸºç¡€æ•°æ®
    print("\nğŸ“¥ æ·»åŠ åŸºç¡€çŸ¥è¯†åˆ°KG...")
    
    kg.add_entity(
        "typhoon_meihua",
        "å°é£æ¢…èŠ±",
        "å°é£",
        {
            "year": 2022,
            "max_wind_speed": 55,
            "min_pressure": 920,
            "intensity": "è¶…å¼ºå°é£"
        }
    )
    
    kg.add_entity(
        "region_zhejiang",
        "æµ™æ±Ÿ",
        "åœ°åŒº",
        {"province": "æµ™æ±Ÿçœ", "coastal": True}
    )
    
    kg.add_relation("typhoon_meihua", "ç™»é™†äº", "region_zhejiang")
    
    print("  âœ“ åŸºç¡€æ•°æ®å·²æ·»åŠ ")
    
    # 3. æµ‹è¯•æŸ¥è¯¢ï¼ˆä¸‰ç§æ¨¡å¼ï¼‰
    print("\n" + "="*70)
    print("ğŸ” æµ‹è¯•æŸ¥è¯¢åŠŸèƒ½")
    print("="*70)
    
    question = "å°é£æ¢…èŠ±åœ¨å“ªé‡Œç™»é™†ï¼Ÿ"
    
    print(f"\né—®é¢˜: {question}\n")
    
    # æ¨¡å¼1ï¼šä»…KG
    print("ã€æ¨¡å¼1ï¼šä»…çŸ¥è¯†å›¾è°±ã€‘")
    answer1 = system.query(question, mode="kg_only")
    print(answer1)
    
    # æ¨¡å¼2ï¼šä»…æ¨¡å‹
    print("\nã€æ¨¡å¼2ï¼šä»…Qwenæ¨¡å‹ã€‘")
    answer2 = system.query(question, mode="model_only")
    print(answer2)
    
    # æ¨¡å¼3ï¼šæ··åˆï¼ˆæ¨èï¼‰
    print("\nã€æ¨¡å¼3ï¼šæ··åˆæ¨¡å¼ï¼ˆæ¨èï¼‰ã€‘")
    answer3 = system.query(question, mode="hybrid")
    print(answer3)
    
    # 4. æµ‹è¯•çŸ¥è¯†ç¼–è¾‘
    print("\n" + "="*70)
    print("âœï¸  æµ‹è¯•çŸ¥è¯†ç¼–è¾‘åŠŸèƒ½")
    print("="*70)
    
    print("\nåœºæ™¯ï¼šæ›´æ­£å°é£æ¢…èŠ±çš„æœ€å¤§é£é€Ÿ")
    print("  åŸå€¼: 55 m/s")
    print("  æ–°å€¼: 58 m/s")
    
    success = system.editor.edit_entity(
        "typhoon_meihua",
        "max_wind_speed",
        58,
        method="both"  # åŒæ—¶æ›´æ–°KGå’Œæ¨¡å‹
    )
    
    if success:
        print("  âœ“ ç¼–è¾‘æˆåŠŸ")
        
        # éªŒè¯æ›´æ–°
        entity = kg.get_entity("typhoon_meihua")
        print(f"  éªŒè¯: æœ€å¤§é£é€Ÿ = {entity['properties']['max_wind_speed']} m/s")
    
    # 5. æµ‹è¯•ä»æ–‡æœ¬æ·»åŠ çŸ¥è¯†
    print("\n" + "="*70)
    print("ğŸ“ æµ‹è¯•ä»æ–‡æœ¬æ·»åŠ çŸ¥è¯†")
    print("="*70)
    
    new_text = """
    å°é£"çƒŸèŠ±"äº2021å¹´7æœˆç™»é™†æµ™æ±Ÿï¼Œ
    æœ€å¤§é£é€Ÿ42ç±³/ç§’ï¼Œå½±å“èŒƒå›´åŒ…æ‹¬æµ™æ±Ÿã€æ±Ÿè‹ã€‚
    """
    
    print(f"\nè¾“å…¥æ–‡æœ¬:\n{new_text}")
    
    extracted = system.add_knowledge_from_text(new_text)
    
    print(f"\næå–ç»“æœ:")
    print(f"  å®ä½“æ•°: {len(extracted.get('entities', []))}")
    print(f"  å…³ç³»æ•°: {len(extracted.get('relations', []))}")
    
    # 6. ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "="*70)
    print("ğŸ“Š çŸ¥è¯†å›¾è°±ç»Ÿè®¡")
    print("="*70)
    
    cursor = kg.conn.cursor()
    
    cursor.execute("SELECT COUNT(*) FROM entities")
    entity_count = cursor.fetchone()[0]
    
    cursor.execute("SELECT COUNT(*) FROM relations")
    relation_count = cursor.fetchone()[0]
    
    cursor.execute("SELECT COUNT(*) FROM edit_history WHERE success = 1")
    edit_count = cursor.fetchone()[0]
    
    print(f"\n  å®ä½“æ€»æ•°: {entity_count}")
    print(f"  å…³ç³»æ€»æ•°: {relation_count}")
    print(f"  ç¼–è¾‘å†å²: {edit_count} æ¬¡æˆåŠŸ")
    
    # 7. æ˜¾ç¤ºç¼–è¾‘å†å²
    print("\nğŸ“œ æœ€è¿‘ç¼–è¾‘å†å²:")
    cursor.execute("""
        SELECT edit_type, entity_or_relation_id, old_value, new_value, method, timestamp
        FROM edit_history
        ORDER BY id DESC
        LIMIT 5
    """)
    
    for row in cursor.fetchall():
        edit_type, entity_id, old, new, method, time = row
        print(f"  [{time[:19]}] {edit_type}")
        print(f"    {entity_id}: {old} â†’ {new} (æ–¹æ³•: {method})")
    
    print("\n" + "="*70)
    print("âœ¨ æ¼”ç¤ºå®Œæˆï¼")
    print("="*70)
    
    print("\nğŸ’¡ åŠŸèƒ½æ€»ç»“:")
    print("  âœ“ çŸ¥è¯†å›¾è°±CRUD")
    print("  âœ“ Qwenæ¨¡å‹é›†æˆ")
    print("  âœ“ ä¸‰ç§æŸ¥è¯¢æ¨¡å¼ï¼ˆKG/æ¨¡å‹/æ··åˆï¼‰")
    print("  âœ“ çŸ¥è¯†ç¼–è¾‘ï¼ˆFT/MEMITï¼‰")
    print("  âœ“ ä»æ–‡æœ¬æå–çŸ¥è¯†")
    print("  âœ“ KGä¸æ¨¡å‹åŒå‘åŒæ­¥")
    print("  âœ“ ç¼–è¾‘å†å²è¿½è¸ª")
    
    print(f"\nğŸ“ æ•°æ®åº“æ–‡ä»¶: {kg.db_path}")


if __name__ == "__main__":
    main()